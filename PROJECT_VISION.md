PROJECT VISION - Single Manuscript AI Revision System (v2.0)
üéØ SINGLE OVERRIDING GOAL
Transform ONE professionally-edited manuscript into its optimal form for agent submission by using AI to identify the best opening (scene or composite) and generate all required revisions with minimal edit burden.
This is a SINGLE-USE, BESPOKE application for ONE AUTHOR, ONE MANUSCRIPT, ONE SUBMISSION CYCLE.

üìñ THE MANUSCRIPT

Status: Professionally edited, well-written prose
Need: Strategic opening selection for maximum market impact
Strategy: Start in medias res with high-impact scene(s)
Challenge: Maintaining narrative coherence with minimal revisions


üöÄ CORE FUNCTIONALITY - THE OPENING LAB
1. Scene-Level Analysis (Not Chapter-Level)
Purpose: Find the best opening at the right granularity
Implementation:
typescriptinterface Scene {
  id: string
  chapterId: string
  text: string
  summary: string
  anchorHash: string  // First/last 12 chars for stable reference
  
  // Scoring (calibrated with exemplars)
  hookScore: number      // Based on rubric + examples
  tensionScore: number   // Conflict density + stakes
  clarityScore: number   // Understandable without context
  
  // Content tracking
  characters: string[]
  reveals: RevealRef[]   // What facts are exposed
  requires: string[]     // What reader must know first
  
  // Metadata
  beats: StoryBeat[]
  location?: string
  timeRef?: string       // Absolute or relative
}
Scene Segmentation:

Break chapters into scenes (rule-based + AI assist)
Detect natural breaks: location changes, time jumps, POV shifts
Each scene gets unique anchor hash for stable reference

2. Reveal Graph & Spoiler Detection
Purpose: Track what the reader knows when
Implementation:
typescriptinterface Reveal {
  id: string
  description: string           // "Sarah is the mole"
  firstExposureSceneId: string  // Where first revealed
  preReqs: string[]             // Other reveals needed first
  type: 'plot' | 'character' | 'world' | 'backstory'
}

interface SpoilerViolation {
  revealId: string
  mentionedIn: TextAnchor  // Quoted span + hash
  shouldAppearIn: string    // Scene where it's properly revealed
  severity: 'critical' | 'moderate' | 'minor'
  fix: AnchoredEdit
}
Spoiler Heatmap: Visual/textual map showing violations when scene X opens
3. Opening Lab - Decision Support
Purpose: Compare up to 5 opening candidates side-by-side
Candidates Can Be:

Single scene
Composite (Scene 23a ‚Üí micro-flashback ‚Üí Scene 23b)
Multi-scene sequence

For Each Candidate, Calculate:
typescriptinterface OpeningAnalysis {
  candidate: OpeningCandidate
  
  // Scores (calibrated)
  hookStrength: number
  clarityUnderColdStart: number
  marketAppeal: number
  
  // Problems
  spoilerViolations: SpoilerViolation[]
  missingContext: ContextGap[]
  
  // Solutions
  editBurden: {
    newWords: number
    changedSpans: number
    percentOfText: number
  }
  requiredPatches: AnchoredEdit[]
  bridgeParagraphs: BridgeDraft[]
  
  // Visualization
  tensionCurve: number[]  // Before/after
}
4. Anchored Recommendations (Not Line Numbers)
Purpose: Recommendations that survive editing
Every Edit References:
typescriptinterface AnchoredEdit {
  anchor: TextAnchor  // Quoted text + hash
  sceneId: string
  
  original: string    // "Sarah's voice, guilty and thin"
  suggested: string   // "Sarah's voice, low and thin"
  reason: string      // "Removes premature reveal of guilt"
  
  type: 'replace' | 'insert' | 'delete'
  priority: 'critical' | 'important' | 'optional'
}

interface TextAnchor {
  quotedSpan: string    // Actual text (15-30 chars)
  hash: string          // Stable identifier
  context: string       // Surrounding text for verification
}
5. Lightweight Retrieval (Not Full RAG)
Purpose: Precise lookups without complexity
Implementation:

Local index of scenes, reveals, dependencies
Quick search: "Where is X first mentioned?"
Cross-reference validation
No external services, no vector DB overhead

Use Cases:

Find all mentions of a character
Locate first reveal of plot point
Verify timeline references
Check for contradiction


üõ†Ô∏è IMPLEMENTATION PLAN - LEAN & FOCUSED
Phase 1: Skeleton (Days 1-3)
bash# Core functionality, no UI
- Scene segmentation from chapters
- Extract reveals, characters, timeline
- Build reveal graph
- Generate scene inventory report
Deliverable: Scene inventory with initial scores
Phase 2: Opening Lab (Days 4-7)
bash# Decision support system
- Score potential openings (3-5 candidates)
- Generate spoiler heatmaps
- Calculate missing context
- Compute edit burden
- Export comparison report (Markdown/PDF)
Deliverable: Opening comparison report with recommendations
Phase 3: Patch Packs (Days 8-11)
bash# Specific revision guidance
- Generate anchored micro-edits
- Draft bridge paragraphs
- Create side-by-side diffs
- Overlay tension curves
Deliverable: Detailed revision instructions with anchored edits
Phase 4: Export & Validate (Days 12-14)
bash# Submission-ready output
- Apply selected revisions
- Run continuity checks
- Generate DOCX with/without Track Changes
- Create synopsis (1-2 pages)
- Write "Why this opening" memo
Deliverable: Agent submission bundle

üìä SUCCESS METRICS - OUTCOME FOCUSED
Must-Have Metrics

Opening decision confidence ‚â• 80% (you're certain it's the right choice)
Zero spoiler violations in final version
Edit burden ‚â§ 10% of opening pages
Cold-reader retention: 2 of 3 readers continue past page 5

Nice-to-Have Metrics

Continuity score: 100% (no timeline/fact contradictions)
Submission bundle complete in under 2 weeks
Version comparison clarity (can see exactly what changed)


üí° CRITICAL DECISIONS
What We're Building
‚úÖ Opening Lab - Compare 3-5 scene-based openings
‚úÖ Reveal Graph - Track what reader knows when
‚úÖ Spoiler Heatmap - Visual violation detection
‚úÖ Anchored Edits - Survive text changes
‚úÖ Bridge Paragraphs - AI-drafted transitions
‚úÖ Export Bundle - DOCX + synopsis + memo
What We're NOT Building
‚ùå Full manuscript reordering (just opening)
‚ùå Complex UI (reports + exports are enough)
‚ùå Real-time editing (batch revisions)
‚ùå Multiple manuscripts
‚ùå Publishing workflow beyond submission
Technology Choices

AI: Claude 3.5 Sonnet (primary), GPT-4 Turbo (backup)
Retrieval: Local index, no external DB
Anchoring: Quoted spans + hashes, not line numbers
Versions: Diffs + patches, not just snapshots
Privacy: Local-only processing, no external retention


‚ö° EXAMPLE OUTPUT - ANCHORED RECOMMENDATION
markdownOPENING CANDIDATE: Scene 23a (Warehouse Raid)

SPOILER VIOLATIONS: 2 found

1. REVEAL S-014: "Sarah is the mole"
   FOUND IN: "Sarah's voice, guilty and thin" [Scene 23a, anchor d3fa...a9]
   FIX: Replace "guilty" with "low"
   REASON: Premature reveal of Sarah's betrayal (properly revealed Scene 47)

2. REVEAL S-007: "Virus is engineered"  
   FOUND IN: "a lab-born heat that licks" [Scene 23a, anchor 8b21...33]
   FIX: Replace "lab-born" with "unnatural"
   REASON: Reveals artificial origin too early

MISSING CONTEXT: 3 items

1. WHO IS MARCUS?
   INSERT AFTER: "Marcus checked his watch" [anchor c2e9...15]
   DRAFT: "Marcus, fifteen years of field ops etched in his movements"

2. RAID OBJECTIVE?
   INSERT AFTER: "We moved toward the door" [anchor a411...22]
   DRAFT: "The coolant keys had to be here‚ÄîJensen's last intel was never wrong"

3. WHERE/WHEN?
   INSERT AT: Opening of scene [anchor 0000...00]
   DRAFT: "Dockside. 03:12. Rain hammered the tin roof like accusations"

EDIT BURDEN: 7.3% of text (acceptable)

üö® CORE PRINCIPLES

Scenes are atoms, not chapters
Anchors are references, not line numbers
Reveals are tracked, creating spoiler detection
Edit burden is measured, keeping changes minimal
Cold-reader clarity is the north star


üìù CURRENT STATUS

 Manuscript loaded and segmented into scenes
 Reveal graph built and validated
 Opening candidates identified (3-5 scenes)
 Spoiler heatmaps generated
 Edit burden calculated for each
 Opening selected with confidence
 Anchored edits generated
 Bridge paragraphs drafted
 Revisions applied
 Continuity validated
 Export bundle created
 Cold-reader test passed


üéØ NORTH STAR - OUTCOME
When complete, you can say:

"The Opening Lab analyzed my manuscript at the scene level and showed me exactly how starting with Scene 23a would work‚Äîincluding a spoiler heatmap showing two reveals that needed fixing, three pieces of missing context to add, and the exact 7% edit burden. Every recommendation was anchored to quoted text that survived my edits. I applied the changes, validated continuity, and exported a submission bundle with the new opening, updated synopsis, and a one-page 'Why this opening' memo for agents."

THAT'S THE DELIVERABLE. A SUBMISSION-READY OPENING WITH MINIMAL, PRECISE REVISIONS.